{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Celeb A - phase 2\n",
    "---\n",
    "\n",
    "Without batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/mnt/data/anaconda3/envs/pconv-keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/mnt/data/anaconda3/envs/pconv-keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/mnt/data/anaconda3/envs/pconv-keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/mnt/data/anaconda3/envs/pconv-keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/mnt/data/anaconda3/envs/pconv-keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/mnt/data/anaconda3/envs/pconv-keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pconv_keras.util import MaskGenerator\n",
    "from pconv_keras.generator import AugmentingDataGenerator\n",
    "from pconv_keras.pconv_model import PConvUnet\n",
    "\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, LambdaCallback\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from IPython.display import clear_output\n",
    "\n",
    "BATCH_SIZE=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Test & Train Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 141819 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Create training generator\n",
    "train_datagen = AugmentingDataGenerator(  \n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    pd.read_csv(\"/mnt/data/data/celeba/train.csv\"),\n",
    "    MaskGenerator(256, 256, 3),\n",
    "    folder='/mnt/data/data/celeba/',\n",
    "    target_size=(256, 256), \n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20260 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Create validation generator\n",
    "val_datagen = AugmentingDataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    pd.read_csv(\"/mnt/data/data/celeba/val.csv\"), \n",
    "    MaskGenerator(256, 256, 3), \n",
    "    folder='/mnt/data/data/celeba/',\n",
    "    target_size=(256,256), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40520 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Create testing generator\n",
    "test_datagen = AugmentingDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    pd.read_csv(\"/mnt/data/data/celeba/test.csv\"), \n",
    "    MaskGenerator(256, 256, 3), \n",
    "    folder='/mnt/data/data/celeba/',\n",
    "    target_size=(256, 256), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick out an example\n",
    "test_data = next(test_generator)\n",
    "(masked, mask), ori = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_callback(model, folder):\n",
    "    \"\"\"Called at the end of each epoch, displaying our previous test images,\n",
    "    as well as their masked predictions and saving them to disk\"\"\"\n",
    "    \n",
    "    # Get samples & Display them        \n",
    "    pred_img = model.predict([masked, mask])\n",
    "    pred_time = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "    # Clear current output and display test images\n",
    "    for i in range(len(ori)):\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "        axes[0].imshow(masked[i,:,:,:])\n",
    "        axes[1].imshow(pred_img[i,:,:,:] * 1.)\n",
    "        axes[2].imshow(ori[i,:,:,:])\n",
    "        axes[0].set_title('Masked Image')\n",
    "        axes[1].set_title('Predicted Image')\n",
    "        axes[2].set_title('Original Image')\n",
    "                \n",
    "        plt.savefig(os.path.join(folder, f\"00img_{i}_{pred_time}.png\"))\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2 - without batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights from previous run\n",
    "model = PConvUnet(img_rows=256, img_cols=256,\n",
    "                   vgg_weights=r\"/mnt/data/train_camp/pconv_keras_imagenet/pytorch_to_keras_vgg16.h5\")\n",
    "model.load(\n",
    "    r\"/mnt/data/train_camp/pconv_keras_celeba/imagenet_phase2/weights.01-1.30.h5\",\n",
    "#     r\"/mnt/data/train_camp/pconv_keras_celeba/imagenet_phase1_paperMasks/weights.09-1.23.h5\",\n",
    "    train_bn=False,\n",
    "    lr=0.00005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = r'/mnt/data/train_camp/pconv_keras_celeba/imagenet_phase2/'\n",
    "TEST_SAMPLE_FOLDER = os.path.join(FOLDER, 'test_samples')\n",
    "if not os.path.isdir(TEST_SAMPLE_FOLDER):\n",
    "    os.makedirs(TEST_SAMPLE_FOLDER)\n",
    "    \n",
    "plot_callback(model, TEST_SAMPLE_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training for certain amount of epochs\n",
    "model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch=len(train_datagen.generator),\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_datagen.generator),\n",
    "    epochs=10,  \n",
    "#     verbose=0,\n",
    "    callbacks=[\n",
    "        TensorBoard(\n",
    "            log_dir=FOLDER,\n",
    "            write_graph=False\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            os.path.join(FOLDER, 'weights.{epoch:02d}-{loss:.2f}.h5'),\n",
    "            monitor='val_loss', \n",
    "            save_best_only=True, \n",
    "            save_weights_only=True\n",
    "        ),\n",
    "        LambdaCallback(\n",
    "            on_epoch_end=lambda epoch, logs: plot_callback(model, TEST_SAMPLE_FOLDER)\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FINISHED!!!!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
