{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet Partial Convolution\n",
    "----\n",
    "Copied from https://github.com/MathiasGruber/PConv-Keras/blob/master/notebooks/Step4%20-%20Imagenet%20Training.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, LambdaCallback\n",
    "from keras import backend as K\n",
    "from keras.utils import Sequence\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Change to root path\n",
    "# if os.path.basename(os.getcwd()) != 'PConv-Keras':\n",
    "#     os.chdir(r\"/mnt/data/PConv-Keras\")    \n",
    "# import sys\n",
    "# sys.path.append(r\"/mnt/data/PConv-Keras\")\n",
    "\n",
    "from libs.pconv_model import PConvUnet\n",
    "from libs.util import MaskGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTINGS\n",
    "TRAIN_DIR = r\"/mnt/data/data/imagenet/ILSVRC/Data/CLS-LOC/train\"\n",
    "VAL_DIR = r\"/mnt/data/data/imagenet/ILSVRC/Data/CLS-LOC/\"\n",
    "TEST_DIR = r\"/mnt/data/data/imagenet/ILSVRC/Data/CLS-LOC/\"\n",
    "\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating train & test data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentingDataGenerator(ImageDataGenerator):\n",
    "    def flow_from_directory(self, directory, mask_generator, *args, **kwargs):\n",
    "        generator = super().flow_from_directory(directory, class_mode=None, *args, **kwargs)        \n",
    "        seed = None if 'seed' not in kwargs else kwargs['seed']\n",
    "        while True:\n",
    "            \n",
    "            # Get augmentend image samples\n",
    "            ori = next(generator)\n",
    "\n",
    "            # Get masks for each image sample            \n",
    "            mask = np.stack([\n",
    "                mask_generator.sample(seed)\n",
    "                for _ in range(ori.shape[0])], axis=0\n",
    "            )\n",
    "\n",
    "            # Apply masks to all image sample\n",
    "            masked = deepcopy(ori)\n",
    "            masked[mask==0] = 1\n",
    "\n",
    "            # Yield ([ori, masl],  ori) training batches\n",
    "#             print(masked.shape, ori.shape)\n",
    "            gc.collect()\n",
    "            yield [masked, mask], ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training generator\n",
    "train_datagen = AugmentingDataGenerator(  \n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR, \n",
    "    MaskGenerator(512, 512, 3),\n",
    "    target_size=(512, 512), \n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation generator\n",
    "val_datagen = AugmentingDataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    VAL_DIR, \n",
    "    MaskGenerator(512, 512, 3), \n",
    "    target_size=(512, 512), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    classes=['val'], \n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create testing generator\n",
    "test_datagen = AugmentingDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR, \n",
    "    MaskGenerator(512, 512, 3), \n",
    "    target_size=(512, 512), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    classes=['test'],\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick out an example\n",
    "test_data = next(test_generator)\n",
    "(masked, mask), ori = test_data\n",
    "\n",
    "# Show side by side\n",
    "for i in range(len(ori)):\n",
    "    _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    axes[0].imshow(masked[i,:,:,:])\n",
    "    axes[1].imshow(mask[i,:,:,:] * 1.)\n",
    "    axes[2].imshow(ori[i,:,:,:])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_callback(model, folder):\n",
    "    \"\"\"Called at the end of each epoch, displaying our previous test images,\n",
    "    as well as their masked predictions and saving them to disk\"\"\"\n",
    "    \n",
    "    # Get samples & Display them        \n",
    "    pred_img = model.predict([masked, mask])\n",
    "    pred_time = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "    # Clear current output and display test images\n",
    "    for i in range(len(ori)):\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "        axes[0].imshow(masked[i,:,:,:])\n",
    "        axes[1].imshow(pred_img[i,:,:,:] * 1.)\n",
    "        axes[2].imshow(ori[i,:,:,:])\n",
    "        axes[0].set_title('Masked Image')\n",
    "        axes[1].set_title('Predicted Image')\n",
    "        axes[2].set_title('Original Image')\n",
    "                \n",
    "        plt.savefig(os.path.join(folder, f\"00img_{i}_{pred_time}.png\"))\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_print_callback = LambdaCallback(\n",
    "    on_epoch_begin=lambda epoch, logs: print(f\"Epoch {epoch}:\", flush=True, end=''),\n",
    "    on_batch_begin=lambda batch, logs: print(\".\", flush=True, end=''),\n",
    "    on_epoch_end=lambda epoch, logs: print(\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1 - with batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = PConvUnet(vgg_weights=r\"/mnt/data/train_camp/pconv_keras_imagenet/pytorch_to_keras_vgg16.h5\")\n",
    "FOLDER = r'/mnt/data/train_camp/pconv_keras_imagenet/imagenet_phase1_paperMasks'\n",
    "TEST_SAMPLE_FOLDER = os.path.join(FOLDER, 'test_samples')\n",
    "if not os.path.isdir(TEST_SAMPLE_FOLDER):\n",
    "    os.makedirs(TEST_SAMPLE_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training for certain amount of epochs\n",
    "model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch=10000,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=1000,\n",
    "    epochs=50,  \n",
    "    verbose=0,\n",
    "    callbacks=[\n",
    "        TensorBoard(\n",
    "            log_dir=FOLDER,\n",
    "            write_graph=False\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            FOLDER+'weights.{epoch:02d}-{loss:.2f}.h5',\n",
    "            monitor='val_loss', \n",
    "            save_best_only=True, \n",
    "            save_weights_only=True\n",
    "        ),\n",
    "        batch_print_callback,\n",
    "        LambdaCallback(\n",
    "            on_epoch_end=lambda epoch, logs: plot_callback(model, TEST_SAMPLE_FOLDER)\n",
    "        )#,TQDMNotebookCallback()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FINISHED!!!!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
